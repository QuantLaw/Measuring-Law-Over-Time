{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Community Sankey Plot\n",
    "\n",
    "In this notebook, we mainly create Figure 5 and the analogue figures from the SI.\n",
    "We further inspect the contents of the Miscellaneous category, which are also discussed in the SI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:22.314954Z",
     "iopub.status.busy": "2021-03-07T13:00:22.313768Z",
     "iopub.status.idle": "2021-03-07T13:00:23.895753Z",
     "shell.execute_reply": "2021-03-07T13:00:23.896448Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import regex\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from quantlaw.utils.networkx import hierarchy_graph\n",
    "from legal_data_clustering.utils.graph_api import (\n",
    "    cluster_families,\n",
    "    add_community_to_graph,\n",
    "    get_clustering_result,\n",
    "    get_heading_path,\n",
    "    add_headings_path\n",
    ")\n",
    "\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.901810Z",
     "iopub.status.busy": "2021-03-07T13:00:23.900898Z",
     "iopub.status.idle": "2021-03-07T13:00:23.904265Z",
     "shell.execute_reply": "2021-03-07T13:00:23.903540Z"
    }
   },
   "outputs": [],
   "source": [
    "def cluster_family_plt_colors(dataset):\n",
    "    colors = np.array(\n",
    "        [np.array([*c, 1]) for c in sns.color_palette(\"tab20\")] +\n",
    "        [np.array([0.75, 0.75, 0.75, 1])]\n",
    "    )\n",
    "    return ListedColormap(colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.931056Z",
     "iopub.status.busy": "2021-03-07T13:00:23.930218Z",
     "iopub.status.idle": "2021-03-07T13:00:23.932600Z",
     "shell.execute_reply": "2021-03-07T13:00:23.933222Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_level_node_weights(G, level):\n",
    "    \"\"\"\n",
    "    Gets all weights of nodes of a given level.\n",
    "    Used e.g. to obtain the total weight of level.\n",
    "    \"\"\"\n",
    "    return [data['weight'] for node_key, data in G.nodes(data=True) if data['bipartite'] == level]\n",
    "\n",
    "def calc_config(G, spline_node_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Calculate basic parameters to plot based on the input graph G.\n",
    "    \"\"\"\n",
    "    config = dict()\n",
    "    config['levels'] = sorted(set(nx.get_node_attributes(G, 'bipartite').values()), key=lambda x: x.lower())\n",
    "    config['levels_node_weight_sum'] = {\n",
    "        level: \n",
    "        sum(get_level_node_weights(G, level))\n",
    "        for level in config['levels']\n",
    "    }\n",
    "    config['x_weight_scale'] = max(config['levels_node_weight_sum'].values()) # number so chars that are represented by 100% of the width of the plot\n",
    "    config['node_height'] = 1/len(config['levels'])*(1-spline_node_ratio) # height of nodes\n",
    "    config['spline_height'] = 1/(len(config['levels'])-1)*spline_node_ratio # height of splines\n",
    "    \n",
    "    config['level_tick_positions'] = list(reversed([\n",
    "        (config['node_height'] + config['spline_height']) * idx + config['node_height'] / 2\n",
    "        for idx, level in enumerate(config['levels'])\n",
    "    ]))\n",
    "    return config\n",
    "\n",
    "def calc_node_positions(G, config, level_node_orders):\n",
    "    \"\"\"\n",
    "    Calculates the positions of the nodes\n",
    "    \"\"\"\n",
    "    positions = {}\n",
    "\n",
    "    for level_idx, level in enumerate(config['levels']):\n",
    "        left = 0\n",
    "\n",
    "        # Center\n",
    "        left = (1 - config['levels_node_weight_sum'][level]/config['x_weight_scale']) / 2\n",
    "\n",
    "        for node_idx, node in enumerate(level_node_orders[level]):\n",
    "            height = config['node_height']\n",
    "            width = G.nodes[node]['weight']/config['x_weight_scale']\n",
    "\n",
    "            top = 1 - (config['node_height'] + config['spline_height']) * level_idx\n",
    "            bottom = top - height\n",
    "\n",
    "            positions[node] = dict(\n",
    "                height=height,\n",
    "                width=width,\n",
    "                top=top,\n",
    "                bottom=bottom,\n",
    "                left=left,\n",
    "            )\n",
    "\n",
    "            left += width\n",
    "\n",
    "    \n",
    "    return positions\n",
    "\n",
    "def calc_edge_positions(G, node_positions, config, level_node_orders):\n",
    "    \"\"\"\n",
    "    Calculates the position of the edges.\n",
    "    \"\"\"\n",
    "    edge_positions = {}\n",
    "\n",
    "    edge_start_left_offset = {node: 0 for node in node_positions.keys()}\n",
    "    edge_end_left_offset = {node: 0 for node in node_positions.keys()}\n",
    "\n",
    "    global_node_order = list(itertools.chain.from_iterable(\n",
    "        [level_node_orders[level] for level in config['levels']]\n",
    "    ))\n",
    "\n",
    "    edges = sorted(\n",
    "        [(u, v) for (u, v) in G.edges], \n",
    "        key=lambda x: (\n",
    "            global_node_order.index(x[0]),\n",
    "            global_node_order.index(x[1]),\n",
    "        ),\n",
    "    )\n",
    "    for u, v in edges:\n",
    "        start_offset = edge_start_left_offset[u]\n",
    "        end_offset = edge_end_left_offset[v]\n",
    "        \n",
    "        y0 = node_positions[u]['bottom']\n",
    "        x0 = node_positions[u]['left'] + start_offset\n",
    "        yn = node_positions[v]['top']\n",
    "        xn = node_positions[v]['left'] + end_offset\n",
    "        width = G.edges[u, v]['weight'] / config['x_weight_scale']\n",
    "\n",
    "        edge_start_left_offset[u] += width\n",
    "        edge_end_left_offset[v] += width\n",
    "\n",
    "        edge_positions[(u, v)] = dict(\n",
    "            x0=x0,\n",
    "            xn=xn,\n",
    "            y0=y0,\n",
    "            yn=yn,\n",
    "            width=width,\n",
    "        )\n",
    "        \n",
    "    return edge_positions\n",
    "\n",
    "\n",
    "def draw_node(ax, left, bottom, top, width, height, label=None, color='k', v_position='center', label_rotation=0):\n",
    "    \"\"\"\n",
    "    Draws a node\n",
    "    \"\"\"\n",
    "    patch = patches.Rectangle(\n",
    "            (\n",
    "                left,\n",
    "                bottom,\n",
    "            ),\n",
    "            width,\n",
    "            height,\n",
    "            color=color\n",
    "         )\n",
    "    patch.set_edgecolor('k')  \n",
    "    patch.set_linewidth('0')\n",
    "    ax.add_patch(patch)\n",
    "    \n",
    "def draw_label(ax, left, bottom, top, width, height, label=None, color='k', v_position='center', label_rotation=0, min_font_size=3):\n",
    "    if v_position == 'bottom':\n",
    "        hpos = bottom + height/3\n",
    "    elif v_position == 'top':\n",
    "        hpos = bottom + height/3*2\n",
    "    else:\n",
    "        hpos = bottom + height/2\n",
    "\n",
    "    if label:\n",
    "        if label_rotation:\n",
    "            fontsize = 2 + 6 * width / 0.02\n",
    "            fontsize = min(fontsize, 8)\n",
    "            if min_font_size:\n",
    "                fontsize = max(fontsize, min_font_size)\n",
    "            xoffset = 0.0006\n",
    "            yoffset = 0\n",
    "        else:\n",
    "            fontsize = 6\n",
    "            xoffset = 0\n",
    "            yoffset = -0.0006\n",
    "        ax.annotate(\n",
    "            str(label),\n",
    "            (left + width/2 + xoffset, hpos + yoffset),\n",
    "            color='k', \n",
    "            weight='bold', \n",
    "            ha='center', \n",
    "            va='center',\n",
    "            fontsize=fontsize,\n",
    "            rotation=label_rotation,\n",
    "        )\n",
    "        \n",
    "        \n",
    "def get_blueprint_vals(resolution):\n",
    "    \"\"\"\n",
    "    Creates a blueprint that can be transformed to print the splines.\n",
    "    \"\"\"\n",
    "    x = np.array([0, 0.15, 0.5, 0.85, 1])\n",
    "    y = np.linspace(0, 1, len(x))\n",
    "    z = np.polyfit(y, x, 4)\n",
    "    f = np.poly1d(z)\n",
    "    blueprint_y_vals = np.linspace(y[0], y[-1], resolution)\n",
    "    blueprint_x_vals = f(blueprint_y_vals)\n",
    "    return blueprint_x_vals, blueprint_y_vals\n",
    "\n",
    "\n",
    "blueprint_x_vals, blueprint_y_vals = get_blueprint_vals(50)\n",
    "\n",
    "\n",
    "def draw_edge(ax, x0, xn, y0, yn, width, \n",
    "             blueprint_x_vals=blueprint_x_vals, blueprint_y_vals=blueprint_y_vals, \n",
    "             color='k', alpha=0.5, hatch=None):\n",
    "    \"\"\"\n",
    "    Draws a node\n",
    "    \"\"\"\n",
    "    y_scale = yn - y0\n",
    "    ty = blueprint_y_vals * y_scale + y0\n",
    "    x_scale = xn - x0\n",
    "    tx = blueprint_x_vals * x_scale + x0\n",
    "    y_new = np.concatenate([ty, ty[::-1], ])\n",
    "    x_new = np.concatenate([tx, tx[::-1] + width, ])\n",
    "    result = np.array([x_new, y_new]).transpose()\n",
    "    ax.add_patch(\n",
    "        patches.Polygon(result, facecolor=color, alpha=alpha, lw=0, hatch=hatch, edgecolor='k')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.949540Z",
     "iopub.status.busy": "2021-03-07T13:00:23.947522Z",
     "iopub.status.idle": "2021-03-07T13:00:23.950850Z",
     "shell.execute_reply": "2021-03-07T13:00:23.951360Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_edges(G, threshold, attr='weight'):\n",
    "    edges_to_remove = [\n",
    "        (u, v) \n",
    "        for u, v, data in G.edges(data=True) \n",
    "        if (\n",
    "            data[attr] < G.nodes[u][attr] * threshold or\n",
    "            data[attr] < G.nodes[v][attr] * threshold \n",
    "        )\n",
    "    ]\n",
    "    H = G.copy()\n",
    "    H.remove_edges_from(edges_to_remove)\n",
    "    return H\n",
    "\n",
    "def load_graph(path, nodes_per_year, edge_threshold):\n",
    "    # Load graph\n",
    "    orig_G = nx.read_gpickle(path)\n",
    "    G = orig_G.copy()\n",
    "    \n",
    "    # Selecte property for weights in plot\n",
    "    nx.set_node_attributes(G, nx.get_node_attributes(G, 'tokens_n'), 'weight')\n",
    "    nx.set_edge_attributes(G, nx.get_edge_attributes(G, 'tokens_n'), 'weight')\n",
    "    \n",
    "    # Remove insignificant edges\n",
    "    G = filter_edges(G, threshold=edge_threshold)\n",
    "    \n",
    "    # Get nodes by snapshot\n",
    "    years = sorted(set(nx.get_node_attributes(G, 'bipartite').values()))\n",
    "    node_years = [\n",
    "        sorted(\n",
    "            [\n",
    "                (n, data['weight']) \n",
    "                for n, data in G.nodes(data=True) \n",
    "                if data['bipartite'] == year\n",
    "            ], \n",
    "            key=lambda tup: tup[-1], reverse=True\n",
    "        ) \n",
    "        for year in years\n",
    "    ]\n",
    "    \n",
    "    # Split nodes in big nodes (displayed) and small nodes (summarized in misc)\n",
    "    big_nodes = [\n",
    "        node[0]\n",
    "        for nodes in node_years\n",
    "        for node in nodes[:nodes_per_year]\n",
    "    ]\n",
    "    \n",
    "    small_nodes = [\n",
    "        node[0]\n",
    "        for nodes in node_years\n",
    "        for node in nodes[nodes_per_year:]\n",
    "    ]\n",
    "    \n",
    "    # Build graph in which small nodes are summarized in misc\n",
    "    H = nx.subgraph(G, big_nodes).copy()\n",
    "    \n",
    "    # Map small nods to corresponding misc node\n",
    "    small_nodes_mapper = dict() \n",
    "    for year, nodes in zip(years, node_years):\n",
    "        for node, data in nodes[nodes_per_year:]:\n",
    "            small_nodes_mapper[node] = f'misc_{year}'\n",
    "    \n",
    "    # calculate weight of misc nodes\n",
    "    misc_weights = {f'misc_{year}': 0 for year in years}\n",
    "    for small_node in small_nodes:\n",
    "        weight = G.nodes[small_node]['weight']\n",
    "        misc_node_key = small_nodes_mapper[small_node]\n",
    "        misc_weights[misc_node_key] += weight\n",
    "    \n",
    "    # add misc nodes to graph\n",
    "    H.add_nodes_from([\n",
    "        (k, dict(weight=w, bipartite=k.split('_')[-1])) \n",
    "        for k, w in misc_weights.items()\n",
    "    ])\n",
    "       \n",
    "    # get edges regarding misc nodes \n",
    "    edges_to_merge = [\n",
    "        (u, v, d)\n",
    "        for u, v, d in G.edges(data=True)\n",
    "        if not (u in big_nodes and v in big_nodes)\n",
    "    ]\n",
    "        \n",
    "    # calculate weight of misc edges\n",
    "    for u, v, d in edges_to_merge:\n",
    "        u_mapped = small_nodes_mapper.get(u, u)\n",
    "        v_mapped = small_nodes_mapper.get(v, v)\n",
    "        if H.has_edge(u_mapped, v_mapped):\n",
    "            H.edges[u_mapped, v_mapped]['weight'] += d['weight']\n",
    "        else:\n",
    "            H.add_edge(u_mapped, v_mapped, weight=d['weight'])   \n",
    "     \n",
    "    # filter edges by absolute weight\n",
    "# Outdated. We filter now by relativ weight to the source and target node. See above.\n",
    "#     edges = [(u, v) for u, v, data in H.edges(data=True) if data['weight'] < edge_threshold]\n",
    "#     print(f'Removes {len(edges)} of {len(H.edges)} edges ({len(edges)/len(H.edges)*100:.1f}%).')\n",
    "#     H.remove_edges_from(edges)\n",
    "#     print(f'Remaining {len(H.edges)/(len(years)-1)} edges per year mapping')\n",
    "        \n",
    "    return H, orig_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.956944Z",
     "iopub.status.busy": "2021-03-07T13:00:23.956154Z",
     "iopub.status.idle": "2021-03-07T13:00:23.958261Z",
     "shell.execute_reply": "2021-03-07T13:00:23.958755Z"
    }
   },
   "outputs": [],
   "source": [
    "def order_nodes_by_weight(config, G):\n",
    "    return {\n",
    "        level:\n",
    "        sorted([n for n, data in G.nodes(data=True) if data['bipartite'] == level], key=lambda n: (\n",
    "               G.nodes[n]['weight'] \n",
    "               if not n.startswith('misc_')\n",
    "               else -1\n",
    "           ), reverse=True\n",
    "        )  # Order by weight\n",
    "        for level in config['levels']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.963635Z",
     "iopub.status.busy": "2021-03-07T13:00:23.962830Z",
     "iopub.status.idle": "2021-03-07T13:00:23.964949Z",
     "shell.execute_reply": "2021-03-07T13:00:23.965506Z"
    }
   },
   "outputs": [],
   "source": [
    "def order_edges_by_weight(edge_positions):\n",
    "    return sorted(\n",
    "        edge_positions.items(), \n",
    "        key=lambda tup:(\n",
    "            -1\n",
    "            if tup[0][0].startswith('misc_') or tup[0][1].startswith('misc_')\n",
    "            else tup[-1]['width']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Color and label position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.972788Z",
     "iopub.status.busy": "2021-03-07T13:00:23.971998Z",
     "iopub.status.idle": "2021-03-07T13:00:23.974085Z",
     "shell.execute_reply": "2021-03-07T13:00:23.974571Z"
    }
   },
   "outputs": [],
   "source": [
    "def alternating_colors(edge_positions, node_positions, G, level_node_orders):\n",
    "    \"\"\"\n",
    "    sets colors in edge_positions\n",
    "    \"\"\"\n",
    "    # Alternating colors\n",
    "    for nodes_at_level in level_node_orders.values():\n",
    "        for idx, node in enumerate(nodes_at_level):\n",
    "            if idx % 2 == 0:\n",
    "                node_positions[node]['color'] = '0.7'\n",
    "                node_positions[node]['v_position'] = 'top'\n",
    "            else:\n",
    "                node_positions[node]['color'] = '0.6'\n",
    "                node_positions[node]['v_position'] = 'bottom'\n",
    "\n",
    "            for out_edge in G.out_edges(node):\n",
    "                    edge_positions[out_edge]['color'] = node_positions[node]['color']\n",
    "                    \n",
    "    # Special color for misc nodes and corresponding edges\n",
    "    for node in node_positions:\n",
    "        if node.startswith('misc_'):\n",
    "            color ='0.8'\n",
    "            node_positions[node]['color'] = color\n",
    "            node_positions[node]['v_position'] = 'center'\n",
    "            for out_edge in [\n",
    "                *G.out_edges(node),\n",
    "                *G.in_edges(node)\n",
    "            ]:\n",
    "                    edge_positions[out_edge]['color'] = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.982765Z",
     "iopub.status.busy": "2021-03-07T13:00:23.981147Z",
     "iopub.status.idle": "2021-03-07T13:00:23.984110Z",
     "shell.execute_reply": "2021-03-07T13:00:23.984643Z"
    }
   },
   "outputs": [],
   "source": [
    "def color_merges_splits(edge_positions, node_positions, H,):\n",
    "    \"\"\"\n",
    "    Coloring merges, splits, etc.\n",
    "    Colors:\n",
    "    - merge edges: green\n",
    "    - split edges: red\n",
    "    - combined merge and split edges: yellow\n",
    "    - ignored edges: blue\n",
    "    A edge is considered a merge/split edge if the source/target node has a degree > 1 of significant edges. \n",
    "    An edge is significant if its weight is a least the node weight * threshold of the source and target node.\n",
    "    Edges that are not significant are ignored edges.\n",
    "    Edges from or to Misc. nodes are not recolored.\n",
    "    \"\"\"\n",
    "    for edge_key in edge_positions:\n",
    "        u, v = edge_key\n",
    "        if u.startswith('misc_') and v.startswith('misc_'):\n",
    "            continue\n",
    "        if H.has_edge(u, v):\n",
    "            is_u_multi = H.out_degree(u) > 1 and not u.startswith('misc_')\n",
    "            is_v_multi = H.in_degree(v) > 1 and not v.startswith('misc_')\n",
    "            if is_u_multi and is_v_multi:\n",
    "                edge_positions[edge_key]['color'] = 'magenta'\n",
    "                edge_positions[edge_key]['hatch'] = 'X'\n",
    "            elif is_u_multi:\n",
    "                # Split\n",
    "                edge_positions[edge_key]['color'] = 'red'\n",
    "                edge_positions[edge_key]['hatch'] = '/'\n",
    "            elif is_v_multi:\n",
    "                # Merge\n",
    "                edge_positions[edge_key]['color'] = 'blue'\n",
    "                edge_positions[edge_key]['hatch'] = '\\\\'\n",
    "        else:\n",
    "            # This is not used if remove insifnificant edges in the first place \n",
    "            edge_positions[edge_key]['color'] = 'orange'\n",
    "            edge_positions[edge_key]['hatch'] = '|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:23.990957Z",
     "iopub.status.busy": "2021-03-07T13:00:23.989946Z",
     "iopub.status.idle": "2021-03-07T13:00:23.992441Z",
     "shell.execute_reply": "2021-03-07T13:00:23.993168Z"
    }
   },
   "outputs": [],
   "source": [
    "def color_births_deaths(node_positions, H):\n",
    "    years = sorted(set(nx.get_node_attributes(H, 'bipartite').values()))\n",
    "    for node in node_positions:\n",
    "        is_birth = H.nodes[node]['bipartite'] != years[0] and H.in_degree(node) == 0\n",
    "        is_death = H.nodes[node]['bipartite'] != years[-1] and H.out_degree(node) == 0\n",
    "        if is_birth and is_death:\n",
    "            pass\n",
    "            # clusters living in one year only are not highlighted if statement below is commented out\n",
    "            # node_positions[node]['color'] = 'orange'\n",
    "        elif is_birth:\n",
    "            node_positions[node]['color'] = 'gold'\n",
    "        elif is_death:\n",
    "            node_positions[node]['color'] = 'chocolate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:24.000130Z",
     "iopub.status.busy": "2021-03-07T13:00:23.999172Z",
     "iopub.status.idle": "2021-03-07T13:00:24.001453Z",
     "shell.execute_reply": "2021-03-07T13:00:24.001995Z"
    }
   },
   "outputs": [],
   "source": [
    "def color_by_cluster_family(orig_G, node_positions, edge_positions, dataset):\n",
    "    components = cluster_families(orig_G, threshold=0.15)\n",
    "    cmap = cluster_family_plt_colors(dataset)\n",
    "    \n",
    "    components = components[:20]\n",
    "    \n",
    "    order = [c[0] for c in components]\n",
    "    \n",
    "    for order_nr, nodes in enumerate(components):\n",
    "        color = cmap(order_nr)\n",
    "        for node in nodes:\n",
    "            if node in node_positions:\n",
    "                node_positions[node]['color'] = color\n",
    "\n",
    "        for edge in edge_positions:\n",
    "            u, v = edge\n",
    "            if u in nodes or v in nodes:\n",
    "                 edge_positions[edge]['color'] = color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:24.012624Z",
     "iopub.status.busy": "2021-03-07T13:00:24.011674Z",
     "iopub.status.idle": "2021-03-07T13:00:24.015467Z",
     "shell.execute_reply": "2021-03-07T13:00:24.016096Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_evolution_graph(dataset, config_str, nodes_per_year=50, min_font_size=3):\n",
    "    global G, orig_G, node_positions, edge_positions\n",
    "    G, orig_G = load_graph(\n",
    "        path=f'../../legal-networks-data/{dataset.lower()}/13_cluster_evolution_graph/all_{config_str}.gpickle.gz',\n",
    "        nodes_per_year=nodes_per_year,\n",
    "        edge_threshold = .15,\n",
    "    )\n",
    "    \n",
    "    config = calc_config(G)\n",
    "\n",
    "    level_node_orders = order_nodes_by_weight(config, G)\n",
    "\n",
    "    node_positions = calc_node_positions(G, config, level_node_orders)\n",
    "    edge_positions = calc_edge_positions(G, node_positions, config, level_node_orders)\n",
    "\n",
    "    alternating_colors(edge_positions, node_positions, G, level_node_orders)\n",
    "    \n",
    "#     categeories_df = pd.read_csv(f'../{dataset.upper()}-data/cd_8_cluster_categories/all_{config_str}.csv')\n",
    "#     categories_colors(edge_positions, node_positions, categeories_df)\n",
    "    \n",
    "#     color_merges_splits(edge_positions, node_positions, G)\n",
    "#     color_births_deaths(node_positions, G)\n",
    "\n",
    "    color_by_cluster_family(orig_G, node_positions, edge_positions, dataset)\n",
    "            \n",
    "    plt.rcParams['figure.figsize'] = 8, 11\n",
    "    plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    for node, position in node_positions.items():\n",
    "        draw_node(ax=ax, **position)\n",
    "\n",
    "    edge_positions_list = order_edges_by_weight(edge_positions)\n",
    "    for edge, position in edge_positions_list:\n",
    "        draw_edge(ax=ax, **position)\n",
    "\n",
    "    plt.yticks(config['level_tick_positions'], [l[:4] for l in config['levels']], fontsize=12)\n",
    "    plt.xticks([])\n",
    "    filepath_base = f'../graphics/sankey_{dataset.lower()}_{config_str}'\n",
    "    if nodes_per_year != 50:\n",
    "        filepath_base +=f'_miscafter{nodes_per_year or 0}'\n",
    "    plt.savefig(filepath_base + '.pdf')\n",
    "    for node, position in node_positions.items():\n",
    "        community_id = node.split('_')[1]\n",
    "    #     label = ' '.join(\n",
    "    #         [x.split('_')[0][:-1] for x in G.nodes[node].get('law_names', '').split(',')[::2]][:3]\n",
    "    #     )\n",
    "        draw_label(ax=ax, **position, \n",
    "            label=(\n",
    "                'Miscellaneous' \n",
    "                if node.startswith('misc_') else \n",
    "                community_id\n",
    "            ),\n",
    "            label_rotation= 0 if node_positions[node]['v_position'] == 'center' else 90,\n",
    "            min_font_size=min_font_size,\n",
    "        )\n",
    "    plt.savefig(filepath_base + '_labels.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Drawing the Sankey plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:24.020846Z",
     "iopub.status.busy": "2021-03-07T13:00:24.020069Z",
     "iopub.status.idle": "2021-03-07T13:00:24.022458Z",
     "shell.execute_reply": "2021-03-07T13:00:24.022984Z"
    }
   },
   "outputs": [],
   "source": [
    "config_str = '0-0_1-0_-1_a-infomap_n100_m1-0_s0_c1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:00:24.027264Z",
     "iopub.status.busy": "2021-03-07T13:00:24.026459Z",
     "iopub.status.idle": "2021-03-07T13:01:08.640015Z",
     "shell.execute_reply": "2021-03-07T13:01:08.640546Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_evolution_graph('us_reg', config_str, nodes_per_year=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:08.644531Z",
     "iopub.status.busy": "2021-03-07T13:01:08.643851Z",
     "iopub.status.idle": "2021-03-07T13:01:53.018277Z",
     "shell.execute_reply": "2021-03-07T13:01:53.018885Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_evolution_graph('de_reg', config_str, nodes_per_year=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.022537Z",
     "iopub.status.busy": "2021-03-07T13:01:53.021865Z",
     "iopub.status.idle": "2021-03-07T13:01:53.023995Z",
     "shell.execute_reply": "2021-03-07T13:01:53.024522Z"
    }
   },
   "outputs": [],
   "source": [
    "# for config in ['0-0_1-0_-1_a-infomap_m1-0_s0_c1000'] + [\n",
    "#     f'0-0_1-0_-1_a-infomap_n{runs}_m1-0_s0_c1000' for runs in list(range(10,150+1,10)) + [200]\n",
    "# ]:\n",
    "#     plot_evolution_graph('us', config)\n",
    "#     print(config, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.028483Z",
     "iopub.status.busy": "2021-03-07T13:01:53.027645Z",
     "iopub.status.idle": "2021-03-07T13:01:53.029543Z",
     "shell.execute_reply": "2021-03-07T13:01:53.030055Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_evolution_graph('us_reg', config_str, nodes_per_year=500, min_font_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.033969Z",
     "iopub.status.busy": "2021-03-07T13:01:53.033165Z",
     "iopub.status.idle": "2021-03-07T13:01:53.035152Z",
     "shell.execute_reply": "2021-03-07T13:01:53.035656Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_evolution_graph('de', config_str, nodes_per_year=500, min_font_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Miscellaneous category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.044433Z",
     "iopub.status.busy": "2021-03-07T13:01:53.043275Z",
     "iopub.status.idle": "2021-03-07T13:01:53.046345Z",
     "shell.execute_reply": "2021-03-07T13:01:53.045618Z"
    }
   },
   "outputs": [],
   "source": [
    "def inspect_misc(G, orig_G, dataset):\n",
    "    misc_content = defaultdict(list)\n",
    "    for n in sorted(set(orig_G.nodes) - set(G.nodes)):\n",
    "        year = n.split('_')[0]\n",
    "        misc_content[year].extend(\n",
    "            orig_G.nodes[n]['nodes_contained'].split(',')\n",
    "        )\n",
    "    \n",
    "    content = ''\n",
    "    for year in sorted(misc_content.keys()):\n",
    "        H = nx.read_gpickle(f'../../legal-networks-data/{dataset.lower()}/4_crossreference_graph/seqitems/{year}.gpickle.gz')\n",
    "        H = hierarchy_graph(H)\n",
    "        sum_tokens = sum(H.nodes[n]['tokens_n'] for n in misc_content[year])\n",
    "        content += f'{year} | Size of misc in tokens: {sum_tokens}\\n\\n'\n",
    "        for n in sorted(misc_content[year], key=lambda n: -H.nodes[n]['tokens_n']):\n",
    "            content += f\"{H.nodes[n]['tokens_n']:10} | \" + get_heading_path(H, n) + '\\n'\n",
    "        content += '\\n\\n\\n'\n",
    "\n",
    "    with open(f'../results/sankey_misc_inspection_{dataset.lower()}.txt', 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "# for dataset in ['us', 'de']:\n",
    "#     G, orig_G = load_graph(\n",
    "#         path=f'../../legal-networks-data/{dataset.lower()}/13_cluster_evolution_graph/all_{config_str}.gpickle.gz',\n",
    "#         nodes_per_year=50,\n",
    "#         edge_threshold = .15,\n",
    "#     )\n",
    "#     inspect_misc(G, orig_G, dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further layouting and coloring options (not used in the paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring with tab20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.053380Z",
     "iopub.status.busy": "2021-03-07T13:01:53.052368Z",
     "iopub.status.idle": "2021-03-07T13:01:53.054721Z",
     "shell.execute_reply": "2021-03-07T13:01:53.055265Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_colors(G, node_positions, edge_positions, level_node_orders, config, cmap=plt.get_cmap('tab20')):\n",
    "    \"\"\"\n",
    "    Call e.g. \n",
    "    > node_positions, edge_positions = add_colors(G, node_positions, edge_positions, level_node_orders, config, cmap=plt.get_cmap('tab20'))\n",
    "    \"\"\"\n",
    "    cmap_counter = 0\n",
    "\n",
    "    for nodes in [level_node_orders[level] for level in config['levels']]:\n",
    "        for node in nodes:\n",
    "            in_edges = G.in_edges(node)\n",
    "            if not in_edges:\n",
    "                # If no in_edges: get new color\n",
    "                color = cmap(cmap_counter % 20)\n",
    "                cmap_counter += 1\n",
    "            else:\n",
    "                max_in_edge = max(in_edges, key=lambda edge: G.edges[edge]['weight'])\n",
    "                color = edge_positions[max_in_edge]['color']\n",
    "\n",
    "            node_positions[node]['color'] = color\n",
    "            for out_edge in G.out_edges(node):\n",
    "                edge_positions[out_edge]['color'] = color\n",
    "    return node_positions, edge_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sugiyama nodes order\n",
    "\n",
    "Note: This requires the `igraph` library to be installed, which is not among the repository requirements and hence may have to be installed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.062858Z",
     "iopub.status.busy": "2021-03-07T13:01:53.062138Z",
     "iopub.status.idle": "2021-03-07T13:01:53.064313Z",
     "shell.execute_reply": "2021-03-07T13:01:53.064776Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_sugiyama_order(G):\n",
    "    \"\"\"\n",
    "    Use e.g.\n",
    "    > ordering = get_sugiyama_order(G) \n",
    "    > level_node_orders = {\n",
    "    >     level:\n",
    "    >     sorted([n for n, data in G.nodes(data=True) if data['bipartite'] == level], key=lambda n: ordering.index(n)) \n",
    "    >     for level in config['levels']\n",
    "    > }\n",
    "    \"\"\"\n",
    "    import igraph\n",
    "    \n",
    "    nodes = list(G.nodes)\n",
    "    node_weights = [G.nodes[n]['weight'] for n in nodes]\n",
    "    node_bipartite = [G.nodes[n]['bipartite'] for n in nodes]\n",
    "    layers = sorted(set(node_bipartite))\n",
    "    \n",
    "    g = igraph.Graph(directed=True)\n",
    "    g.add_vertices(list(G.nodes))\n",
    "#     g.vs['weight'] = node_weights\n",
    "#     g.vs['bipartite'] = node_bipartite\n",
    "\n",
    "    g.add_edges(G.edges())\n",
    "    \n",
    "    layout = g.layout_sugiyama(layers=[layers.index(x) for x in node_bipartite], weights=node_weights)\n",
    "    \n",
    "    nodes_layout = [(n, *l) for n, l in zip(nodes, layout)]\n",
    "    \n",
    "    y_positions = list(zip(*list(layout)))[1]\n",
    "    assert max(y_positions) == len(layers) - 1\n",
    "    \n",
    "    ordering = [[] for _ in range(len(layers))]\n",
    "    \n",
    "    for node, x, layer in sorted(nodes_layout, key=lambda tup: tup[1]):\n",
    "        ordering[int(layer)].append(node)\n",
    "    return list(itertools.chain(*ordering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring by content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.077533Z",
     "iopub.status.busy": "2021-03-07T13:01:53.076541Z",
     "iopub.status.idle": "2021-03-07T13:01:53.078885Z",
     "shell.execute_reply": "2021-03-07T13:01:53.079465Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_clusterings(config, path, snapshots, dataset):\n",
    "    clusterings = []\n",
    "    for snapshot in snapshots:\n",
    "        clustering = get_clustering_result(\n",
    "            f'{path}/{snapshot}_{config}.json',\n",
    "            dataset,\n",
    "            'seqitems'\n",
    "        )\n",
    "        add_community_to_graph(clustering)\n",
    "        add_headings_path(clustering.graph)\n",
    "        clusterings.append(clustering)\n",
    "        print('\\r' + snapshot, end='')\n",
    "    return clusterings\n",
    "\n",
    "\n",
    "def get_cluster_weights_for_pattern(pattern_str, pattern_key, clusterings, snapshots, G):\n",
    "    pattern = regex.compile(r'[^|]*' + pattern_str + r'[^|]*', flags=regex.IGNORECASE)\n",
    "    # pattern_debug = regex.compile(r'[^|]*' + pattern_str + r'[^|^/]*', flags=regex.IGNORECASE)\n",
    "\n",
    "    for snapshot, clustering in zip(snapshots, clusterings):\n",
    "        texts_matches = [Counter() for cluster in range(len(clustering.communities))]\n",
    "        tokens_n_sizes = [0    for cluster in range(len(clustering.communities))]\n",
    "        tokens_n_matches = [0   for cluster in range(len(clustering.communities))]\n",
    "        \n",
    "        for node in clustering.graph.nodes:\n",
    "            \n",
    "            if clustering.graph.nodes[node].get('type') == 'seqitem' and 'community' in clustering.graph.nodes[node]:\n",
    "                community_idx = clustering.graph.nodes[node]['community']\n",
    "                heading_path = clustering.graph.nodes[node]['heading_path']\n",
    "                tokens_n_sizes[community_idx] += clustering.graph.nodes[node]['tokens_n']\n",
    "                \n",
    "                if pattern.match(heading_path):\n",
    "                    \n",
    "                    tokens_n_matches[community_idx] += clustering.graph.nodes[node]['tokens_n']\n",
    "                    text = node.split('_')[0] # 1 for de and 0 for us\n",
    "                    texts_matches[community_idx].update(\n",
    "                        **{text: clustering.graph.nodes[node]['tokens_n'] }\n",
    "                    )\n",
    "\n",
    "\n",
    "#         weights = [\n",
    "#             (len(pattern.findall(text)) / cnt) if cnt else 0\n",
    "#             for text, cnt in zip(law_name_texts, node_counts)\n",
    "#         ]\n",
    "\n",
    "        for idx, tokens_n_size, tokens_n_match, texts_match in zip(\n",
    "            range(len(tokens_n_sizes)), tokens_n_sizes, tokens_n_matches, texts_matches\n",
    "        ):\n",
    "            node = f'{snapshot}_{idx}'\n",
    "            if G.has_node(node):\n",
    "                G.nodes[f'{snapshot}_{idx}'][pattern_key] = tokens_n_match/tokens_n_size if tokens_n_size else 0\n",
    "                if 'labels' not in  G.node[f'{snapshot}_{idx}']:\n",
    "                    G.nodes[f'{snapshot}_{idx}']['labels'] = Counter()\n",
    "                G.nodes[f'{snapshot}_{idx}']['labels'].update(texts_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample usage (DE data)\n",
    "\n",
    "- Straf\n",
    "- Proze(ss|ß)\n",
    "- steuer\n",
    "- statistik\n",
    "- umwelt\n",
    "- haftung (not so good)\n",
    "- gesellschaft\n",
    "- kapital\n",
    "- gewerbe\n",
    "- arbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.083406Z",
     "iopub.status.busy": "2021-03-07T13:01:53.082606Z",
     "iopub.status.idle": "2021-03-07T13:01:53.084942Z",
     "shell.execute_reply": "2021-03-07T13:01:53.085518Z"
    }
   },
   "outputs": [],
   "source": [
    "# snapshots = [f'{year}' for year in range(1994, 2019)]\n",
    "# clusterings_path = '../US-data/cd_2_cluster_results'\n",
    "# evolution_path = '../US-data/cd_4_cluster_evolution_graph/'\n",
    "# dataset= 'us'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.089467Z",
     "iopub.status.busy": "2021-03-07T13:01:53.088705Z",
     "iopub.status.idle": "2021-03-07T13:01:53.090929Z",
     "shell.execute_reply": "2021-03-07T13:01:53.091448Z"
    }
   },
   "outputs": [],
   "source": [
    "# snapshots = [f'{year}-01-01' for year in range(1994, 2019)]\n",
    "# clusterings_path = '../DE-data/cd_2_cluster_results'\n",
    "# evolution_path = '../DE-data/cd_4_cluster_evolution_graph/'\n",
    "# dataset= 'de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.095128Z",
     "iopub.status.busy": "2021-03-07T13:01:53.094380Z",
     "iopub.status.idle": "2021-03-07T13:01:53.096259Z",
     "shell.execute_reply": "2021-03-07T13:01:53.096735Z"
    }
   },
   "outputs": [],
   "source": [
    "# clusterings = load_clusterings(cluster_config, clusterings_path, snapshots, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.100772Z",
     "iopub.status.busy": "2021-03-07T13:01:53.099975Z",
     "iopub.status.idle": "2021-03-07T13:01:53.102579Z",
     "shell.execute_reply": "2021-03-07T13:01:53.101872Z"
    }
   },
   "outputs": [],
   "source": [
    "# # DE\n",
    "# get_cluster_weights_for_pattern(\n",
    "#     '(straf|ordnungsw)',\n",
    "#     'crim',\n",
    "#     clusterings, snapshots, G\n",
    "# )\n",
    "# get_cluster_weights_for_pattern(\n",
    "#     'steuer',\n",
    "#     'tax',\n",
    "#     clusterings, snapshots, G\n",
    "# )\n",
    "# get_cluster_weights_for_pattern(\n",
    "#     '(umwelt|engerie)',\n",
    "#     'environment',\n",
    "#     clusterings, snapshots, G\n",
    "# )\n",
    "# get_cluster_weights_for_pattern(\n",
    "#     'sozial',\n",
    "#     'social',\n",
    "#     clusterings, snapshots, G\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.107478Z",
     "iopub.status.busy": "2021-03-07T13:01:53.106728Z",
     "iopub.status.idle": "2021-03-07T13:01:53.108821Z",
     "shell.execute_reply": "2021-03-07T13:01:53.109383Z"
    }
   },
   "outputs": [],
   "source": [
    "# # US\n",
    "# get_cluster_weights_for_pattern(\n",
    "#     '(environ|conserva)',\n",
    "#     'environment',\n",
    "#     clusterings, snapshots, G\n",
    "# )\n",
    "# get_cluster_weights_for_pattern(\n",
    "#     'Public\\sHealth\\s.{1,3}\\sWelfare',\n",
    "#     '42',\n",
    "#     clusterings, snapshots, G\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.113901Z",
     "iopub.status.busy": "2021-03-07T13:01:53.113127Z",
     "iopub.status.idle": "2021-03-07T13:01:53.115198Z",
     "shell.execute_reply": "2021-03-07T13:01:53.115801Z"
    }
   },
   "outputs": [],
   "source": [
    "# for node in node_positions:\n",
    "#     colors = [\n",
    "#         plt.get_cmap('Reds')(G.nodes[node]['crim']),\n",
    "#         plt.get_cmap('Blues')(G.nodes[node].get('42', 0)),\n",
    "#         plt.get_cmap('Oranges')(G.nodes[node].get('environment', 0)),\n",
    "#         plt.get_cmap('Greens')(G.nodes[node]['social'])\n",
    "#     ]\n",
    "#     color = [\n",
    "#         max(min(sum(c_channel)-(len(c_channel)-1), 1), 0)\n",
    "#         for c_channel in zip(*colors)\n",
    "#     ]\n",
    "    \n",
    "#     if node.startswith('misc_'):\n",
    "#         color ='0.8'\n",
    "\n",
    "#     node_positions[node]['color'] = color\n",
    "#     for out_edge in G.out_edges(node):\n",
    "#             edge_positions[out_edge]['color'] = color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coloring by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-07T13:01:53.122585Z",
     "iopub.status.busy": "2021-03-07T13:01:53.121875Z",
     "iopub.status.idle": "2021-03-07T13:01:53.123791Z",
     "shell.execute_reply": "2021-03-07T13:01:53.124319Z"
    }
   },
   "outputs": [],
   "source": [
    "def categories_colors(edge_positions, node_positions, categeories_df):\n",
    "    for edge_key in edge_positions:\n",
    "        u, v = edge_key\n",
    "    \n",
    "        if u.startswith('misc') or v.startswith('misc'):\n",
    "            continue\n",
    "            \n",
    "        edge_data = categeories_df[\n",
    "            (categeories_df.from_cluster == u)\n",
    "            & \n",
    "            (categeories_df.to_cluster == v)\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        if len(edge_data) == 1:\n",
    "            event_category = edge_data.iloc[0]['event_category']\n",
    "        else:\n",
    "            assert len(edge_data) == 0\n",
    "            event_category = None\n",
    "        \n",
    "        if event_category == 'split':\n",
    "            edge_positions[edge_key]['color'] = 'red'\n",
    "        elif event_category == 'merge':\n",
    "            edge_positions[edge_key]['color'] = 'green'\n",
    "        elif event_category == 'splerge':\n",
    "            edge_positions[edge_key]['color'] = 'yellow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
